{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Логистическая регрессия. Работа с признаками"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T18:11:48.202066Z",
     "start_time": "2019-10-16T18:11:46.362572Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%pylab is deprecated, use %matplotlib inline and import the required libraries.\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 1. Логистическая регрессия своими руками (4 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полезно [почитать](https://scikit-learn.org/stable/developers/develop.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T18:11:50.932537Z",
     "start_time": "2019-10-16T18:11:50.752839Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class LogReg(BaseEstimator):\n",
    "    def __init__(self,\n",
    "                 gd_type = 'SGD',\n",
    "                 tolerance = 1e-4,\n",
    "                 eta=0.01, # learning_rate\n",
    "                 max_iter=1000,\n",
    "                 w0 = None,\n",
    "                 batch_size = 5):\n",
    "        \"\"\"\n",
    "        gd_type: 'full' or 'SGD' \n",
    "        tolerance: for stopping gradient descent\n",
    "        max_iter: maximum number of steps in gradient descent\n",
    "        w0: np.array of shape (d) — init weights\n",
    "        eta: learning rate\n",
    "        \"\"\"\n",
    "        self.eta = eta\n",
    "        self.max_iter = max_iter\n",
    "        self.tolerance = tolerance\n",
    "        self.w = None\n",
    "        self.loss_history = []\n",
    "        self.gd_type = gd_type\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        функция обучения - разбивается на обучение по двум методам обычному градиенту и стохастическому (мини-батчи)\n",
    "        \"\"\"\n",
    "        self.w = np.zeros(X.shape[1])\n",
    "        for _ in range(self.max_iter):\n",
    "            if self.gd_type == 'gradient':\n",
    "                self.w -= self.eta * self.calc_gradient(X,y)\n",
    "            elif self.gd_type == 'SGD':\n",
    "                i = np.random.choice(X.shape[0],self.batch_size)\n",
    "                self.w -= self.eta * self.calc_gradient(X[i],y[i])\n",
    "            else:\n",
    "                raise ValueError(\"Неправильный метод. Введите 'gradient' or 'SGD'.\")\n",
    "            \n",
    "            loss = self.log_loss(y, self.predict_proba(X))\n",
    "            self.loss_history.append(loss)\n",
    "            if len(self.loss_history) > 1 and abs(self.loss_history[-1] - self.loss_history[-2]) < self.tolerance:\n",
    "                break\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return 1 / (1 + np.exp(-np.dot(X, self.w)))\n",
    "    \n",
    "    def predict(self, X):\n",
    "        proba = self.predict_proba(X)\n",
    "        return (proba > 0.5).astype(int)\n",
    "\n",
    "    def log_loss(self, y, predictions):\n",
    "        return -np.mean(y * np.log(predictions) + (1 - y) * np.log(1 - predictions))\n",
    "    \n",
    "    def calc_gradient(self, X, y):\n",
    "        P = self.predict_proba(X)\n",
    "        gradient = np.dot(X.T, P - y) / X.shape[0]\n",
    "        return gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Синтетические данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%pylab is deprecated, use %matplotlib inline and import the required libraries.\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(\n",
    "    n_samples=100000, n_features=20, n_informative=10, n_redundant=10,\n",
    "    random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Важно:** далее предполагается, что вы используете собственную реализацию логистической регрессии.\n",
    "Если с написанием класса возникли проблемы, используйте реализацию sklearn, чтобы не терять баллы за остальные задания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 3 (1 балл)**\n",
    "\n",
    "Обучите логистическую регрессию на синтетических данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-11T20:39:43.088969Z",
     "start_time": "2018-10-11T20:39:43.084985Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8486666666666667\n",
      "ROC_AUC: 0.9259026444596383\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "prediction = lr.predict(X_test)\n",
    "probs = lr.predict_proba(X_test)\n",
    "\n",
    "print(f'''Accuracy: {accuracy_score(y_test, prediction)}\n",
    "ROC_AUC: {roc_auc_score(y_test, probs[:,1])}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8251\n",
      "ROC_AUC: 0.9064863776281302\n",
      "num_loss: 40\n"
     ]
    }
   ],
   "source": [
    "my_lr = LogReg()\n",
    "my_lr.fit(X_train, y_train)\n",
    "\n",
    "my_prediction = my_lr.predict(X_test)\n",
    "my_probs = my_lr.predict_proba(X_test)\n",
    "\n",
    "print(f'''Accuracy: {accuracy_score(y_test, my_prediction)}\n",
    "ROC_AUC: {roc_auc_score(y_test, my_probs)}\n",
    "num_loss: {len(my_lr.loss_history)}''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <font color='purple'>**Результат:** наша модель справляется не хуже библиотечной)    \n",
    "> Далее будем использовать нашу модель.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На тестовой части посчитайте ROC-AUC, PR-AUC. Постройте ROC и PR кривые. Проинтерпретируйте результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9064863776281302"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_score(y_test, my_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "fpr, tpr, threshold = roc_curve(y_test, my_probs)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.title('ROC-AUC')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, my_probs)\n",
    "\n",
    "plt.title('PR-AUC')\n",
    "plt.plot(precision, recall)\n",
    "plt.ylabel('Recall')\n",
    "plt.xlabel('Precision')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Интерпретация**: \n",
    "\n",
    "> <font color='purple'>**ROC-AUC** показывает долю пар объектов вида (объект класса 1, объект класса 0), которые алгоритм верно упорядочил. В данном случе 0.93 неплохой пезультат.</font>\n",
    "\n",
    "> <font color='purple'>**PR-AUC** рекомендуют использовать в задачах с дисбалансом классов, n/r/ эта кривая точнее описывает правильность классификации объектов с большими оценками, тогда как ROC-кривая — различие распределений объектов разных классов по оценкам.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 2. Работа с категориальными переменными (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этой части мы научимся обрабатывать категориальные переменные, так как закодировать их в виде чисел недостаточно (это задаёт некоторый порядок, которого на категориальных переменных может и не быть). Существует два основных способа обработки категориальных значений:\n",
    "- One-hot-кодирование\n",
    "- Счётчики (CTR, mean-target кодирование, ...) — каждый категориальный признак заменяется на среднее значение целевой переменной по всем объектам, имеющим одинаковое значение в этом признаке.\n",
    "\n",
    "Начнём с one-hot-кодирования. Допустим наш категориальный признак $f_j(x)$ принимает значения из множества $C=\\{c_1, \\dots, c_m\\}$. Заменим его на $m$ бинарных признаков $b_1(x), \\dots, b_m(x)$, каждый из которых является индикатором одного из возможных категориальных значений:\n",
    "$$\n",
    "b_i(x) = [f_j(x) = c_i]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-11T20:41:54.913436Z",
     "start_time": "2018-10-11T20:41:54.907515Z"
    }
   },
   "source": [
    "__Подготовка данных.__\n",
    "\n",
    "Загрузим данные с конкурса  [Kaggle Porto Seguro’s Safe Driver Prediction](https://www.kaggle.com/c/porto-seguro-safe-driver-prediction) (вам нужна только обучающая выборка). Задача состоит в определении водителей, которые в ближайший год воспользуются своей автомобильной страховкой (бинарная классификация). Но для нас важна будет не сама задача, а только её данные. При этом для задания мы немного модифицируем датасет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-12T07:36:04.765536Z",
     "start_time": "2018-10-12T07:35:57.814973Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv', index_col=0)\n",
    "target = data.target.values\n",
    "data = data.drop('target', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пересемплируем выборку так, чтобы положительных и отрицательных объектов в выборке было одинаковое число. Разделим на обучающую и тестовую выборки.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-12T07:36:05.368407Z",
     "start_time": "2018-10-12T07:36:04.770388Z"
    }
   },
   "outputs": [],
   "source": [
    "# some resampling\n",
    "np.random.seed(910)\n",
    "mask_plus = np.random.choice(np.where(target == 1)[0], 100000, replace=True)\n",
    "mask_zero = np.random.choice(np.where(target == 0)[0], 100000, replace=True)\n",
    "\n",
    "data = pd.concat((data.iloc[mask_plus], data.iloc[mask_zero]))\n",
    "target = np.hstack((target[mask_plus], target[mask_zero]))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 5 (0 баллов).** Посчитайте качество (в этом задании будем работать c ROC-AUC) на исходных признаках при применении логистической регрессии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.58932\n",
      "ROC_AUC: 0.623739940981855\n",
      "CPU times: total: 4.14 s\n",
      "Wall time: 1.17 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "prediction = lr.predict(X_test)\n",
    "probs = lr.predict_proba(X_test)\n",
    "\n",
    "print(f'''Accuracy: {accuracy_score(y_test, prediction)}\n",
    "ROC_AUC: {roc_auc_score(y_test, probs[:,1])}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.50884\n",
      "ROC_AUC: 0.5593745260549932\n",
      "num_loss: 1000\n",
      "CPU times: total: 40.3 s\n",
      "Wall time: 10.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "my_lr = LogReg(gd_type = 'gradient')\n",
    "my_lr.fit(X_train.values, y_train)\n",
    "\n",
    "my_prediction = my_lr.predict(X_test.values)\n",
    "my_probs = my_lr.predict_proba(X_test.values)\n",
    "\n",
    "print(f'''Accuracy: {accuracy_score(y_test, my_prediction)}\n",
    "ROC_AUC: {roc_auc_score(y_test, my_probs)}\n",
    "num_loss: {len(my_lr.loss_history)}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.50001\n",
      "ROC_AUC: 0.49159905387902636\n",
      "num_loss: 160\n",
      "CPU times: total: 3.08 s\n",
      "Wall time: 1.13 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "my_lr = LogReg(gd_type = 'SGD')\n",
    "my_lr.fit(X_train.values, y_train)\n",
    "\n",
    "my_prediction = my_lr.predict(X_test.values)\n",
    "my_probs = my_lr.predict_proba(X_test.values)\n",
    "\n",
    "print(f'''Accuracy: {accuracy_score(y_test, my_prediction)}\n",
    "ROC_AUC: {roc_auc_score(y_test, my_probs)}\n",
    "num_loss: {len(my_lr.loss_history)}''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <font color='purple'>**Результат:** тут видно, что на синтетических данных библиотечная модель работает лучше, поэтому берем ее</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 6 (0.5 балла).** Закодируйте все категориальные признаки с помощью one-hot-кодирования. Обучите логистическую регрессию и посмотрите, как изменилось качество модели (с тем, что было до кодирования). Измерьте время, потребовавшееся на обучение модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col</th>\n",
       "      <th>nuniq</th>\n",
       "      <th>d_tp</th>\n",
       "      <th>first_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ps_ind_01</td>\n",
       "      <td>8</td>\n",
       "      <td>ind</td>\n",
       "      <td>[0, 1, 2, 3, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ps_ind_02_cat</td>\n",
       "      <td>5</td>\n",
       "      <td>cat</td>\n",
       "      <td>[1, 2, 3, 4, -1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ps_ind_03</td>\n",
       "      <td>12</td>\n",
       "      <td>ind</td>\n",
       "      <td>[0, 1, 2, 3, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ps_ind_04_cat</td>\n",
       "      <td>3</td>\n",
       "      <td>cat</td>\n",
       "      <td>[0, 1, -1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ps_ind_05_cat</td>\n",
       "      <td>8</td>\n",
       "      <td>cat</td>\n",
       "      <td>[0, 1, 2, 3, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ps_ind_06_bin</td>\n",
       "      <td>2</td>\n",
       "      <td>bin</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ps_ind_07_bin</td>\n",
       "      <td>2</td>\n",
       "      <td>bin</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ps_ind_08_bin</td>\n",
       "      <td>2</td>\n",
       "      <td>bin</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ps_ind_09_bin</td>\n",
       "      <td>2</td>\n",
       "      <td>bin</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ps_ind_10_bin</td>\n",
       "      <td>2</td>\n",
       "      <td>bin</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ps_ind_11_bin</td>\n",
       "      <td>2</td>\n",
       "      <td>bin</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ps_ind_12_bin</td>\n",
       "      <td>2</td>\n",
       "      <td>bin</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ps_ind_13_bin</td>\n",
       "      <td>2</td>\n",
       "      <td>bin</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ps_ind_14</td>\n",
       "      <td>5</td>\n",
       "      <td>ind</td>\n",
       "      <td>[0, 1, 2, 3, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ps_ind_15</td>\n",
       "      <td>14</td>\n",
       "      <td>ind</td>\n",
       "      <td>[0, 1, 2, 3, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ps_ind_16_bin</td>\n",
       "      <td>2</td>\n",
       "      <td>bin</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ps_ind_17_bin</td>\n",
       "      <td>2</td>\n",
       "      <td>bin</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ps_ind_18_bin</td>\n",
       "      <td>2</td>\n",
       "      <td>bin</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ps_reg_01</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>[0.6, 0.8, 0.1, 0.7, 0.4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ps_reg_02</td>\n",
       "      <td>19</td>\n",
       "      <td>None</td>\n",
       "      <td>[0.3, 0.0, 0.6, 0.2, 0.4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ps_reg_03</td>\n",
       "      <td>4399</td>\n",
       "      <td>None</td>\n",
       "      <td>[0.5, 1.8585948994, 1.1241663578, 1.4899664426...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ps_car_01_cat</td>\n",
       "      <td>13</td>\n",
       "      <td>cat</td>\n",
       "      <td>[0, 1, 2, 3, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ps_car_02_cat</td>\n",
       "      <td>2</td>\n",
       "      <td>cat</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ps_car_03_cat</td>\n",
       "      <td>3</td>\n",
       "      <td>cat</td>\n",
       "      <td>[0, 1, -1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ps_car_04_cat</td>\n",
       "      <td>10</td>\n",
       "      <td>cat</td>\n",
       "      <td>[0, 1, 2, 3, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ps_car_05_cat</td>\n",
       "      <td>3</td>\n",
       "      <td>cat</td>\n",
       "      <td>[0, 1, -1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ps_car_06_cat</td>\n",
       "      <td>18</td>\n",
       "      <td>cat</td>\n",
       "      <td>[0, 1, 2, 3, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ps_car_07_cat</td>\n",
       "      <td>3</td>\n",
       "      <td>cat</td>\n",
       "      <td>[0, 1, -1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ps_car_08_cat</td>\n",
       "      <td>2</td>\n",
       "      <td>cat</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ps_car_09_cat</td>\n",
       "      <td>6</td>\n",
       "      <td>cat</td>\n",
       "      <td>[0, 1, 2, 3, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ps_car_10_cat</td>\n",
       "      <td>3</td>\n",
       "      <td>cat</td>\n",
       "      <td>[0, 1, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>ps_car_11_cat</td>\n",
       "      <td>104</td>\n",
       "      <td>cat</td>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ps_car_11</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>[0, 1, 2, 3, -1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>ps_car_12</td>\n",
       "      <td>132</td>\n",
       "      <td>None</td>\n",
       "      <td>[0.5291502621999999, 0.3155946768, 0.5, 0.3160...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>ps_car_13</td>\n",
       "      <td>26545</td>\n",
       "      <td>None</td>\n",
       "      <td>[0.7492282531000001, 1.3741714258000002, 1.584...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>ps_car_14</td>\n",
       "      <td>731</td>\n",
       "      <td>None</td>\n",
       "      <td>[0.4062019202, 0.4283689998, 0.320468407199999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>ps_car_15</td>\n",
       "      <td>15</td>\n",
       "      <td>None</td>\n",
       "      <td>[0.0, 1.0, 2.6457513111, 3.6055512755, 2.44948...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>ps_calc_01</td>\n",
       "      <td>10</td>\n",
       "      <td>calc</td>\n",
       "      <td>[0.9, 0.6, 0.3, 0.2, 0.5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>ps_calc_02</td>\n",
       "      <td>10</td>\n",
       "      <td>calc</td>\n",
       "      <td>[0.6, 0.4, 0.1, 0.8, 0.3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>ps_calc_03</td>\n",
       "      <td>10</td>\n",
       "      <td>calc</td>\n",
       "      <td>[0.6, 0.0, 0.1, 0.3, 0.9]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>ps_calc_04</td>\n",
       "      <td>6</td>\n",
       "      <td>calc</td>\n",
       "      <td>[0, 1, 2, 3, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>ps_calc_05</td>\n",
       "      <td>7</td>\n",
       "      <td>calc</td>\n",
       "      <td>[0, 1, 2, 3, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>ps_calc_06</td>\n",
       "      <td>10</td>\n",
       "      <td>calc</td>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>ps_calc_07</td>\n",
       "      <td>10</td>\n",
       "      <td>calc</td>\n",
       "      <td>[0, 1, 2, 3, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>ps_calc_08</td>\n",
       "      <td>11</td>\n",
       "      <td>calc</td>\n",
       "      <td>[2, 3, 4, 5, 6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>ps_calc_09</td>\n",
       "      <td>8</td>\n",
       "      <td>calc</td>\n",
       "      <td>[0, 1, 2, 3, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>ps_calc_10</td>\n",
       "      <td>24</td>\n",
       "      <td>calc</td>\n",
       "      <td>[0, 1, 2, 3, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>ps_calc_11</td>\n",
       "      <td>17</td>\n",
       "      <td>calc</td>\n",
       "      <td>[0, 1, 2, 3, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>ps_calc_12</td>\n",
       "      <td>9</td>\n",
       "      <td>calc</td>\n",
       "      <td>[0, 1, 2, 3, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>ps_calc_13</td>\n",
       "      <td>14</td>\n",
       "      <td>calc</td>\n",
       "      <td>[0, 1, 2, 3, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>ps_calc_14</td>\n",
       "      <td>23</td>\n",
       "      <td>calc</td>\n",
       "      <td>[0, 1, 2, 3, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>ps_calc_15_bin</td>\n",
       "      <td>2</td>\n",
       "      <td>bin</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>ps_calc_16_bin</td>\n",
       "      <td>2</td>\n",
       "      <td>bin</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>ps_calc_17_bin</td>\n",
       "      <td>2</td>\n",
       "      <td>bin</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>ps_calc_18_bin</td>\n",
       "      <td>2</td>\n",
       "      <td>bin</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>ps_calc_19_bin</td>\n",
       "      <td>2</td>\n",
       "      <td>bin</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>ps_calc_20_bin</td>\n",
       "      <td>2</td>\n",
       "      <td>bin</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               col  nuniq  d_tp  \\\n",
       "0        ps_ind_01      8   ind   \n",
       "1    ps_ind_02_cat      5   cat   \n",
       "2        ps_ind_03     12   ind   \n",
       "3    ps_ind_04_cat      3   cat   \n",
       "4    ps_ind_05_cat      8   cat   \n",
       "5    ps_ind_06_bin      2   bin   \n",
       "6    ps_ind_07_bin      2   bin   \n",
       "7    ps_ind_08_bin      2   bin   \n",
       "8    ps_ind_09_bin      2   bin   \n",
       "9    ps_ind_10_bin      2   bin   \n",
       "10   ps_ind_11_bin      2   bin   \n",
       "11   ps_ind_12_bin      2   bin   \n",
       "12   ps_ind_13_bin      2   bin   \n",
       "13       ps_ind_14      5   ind   \n",
       "14       ps_ind_15     14   ind   \n",
       "15   ps_ind_16_bin      2   bin   \n",
       "16   ps_ind_17_bin      2   bin   \n",
       "17   ps_ind_18_bin      2   bin   \n",
       "18       ps_reg_01     10  None   \n",
       "19       ps_reg_02     19  None   \n",
       "20       ps_reg_03   4399  None   \n",
       "21   ps_car_01_cat     13   cat   \n",
       "22   ps_car_02_cat      2   cat   \n",
       "23   ps_car_03_cat      3   cat   \n",
       "24   ps_car_04_cat     10   cat   \n",
       "25   ps_car_05_cat      3   cat   \n",
       "26   ps_car_06_cat     18   cat   \n",
       "27   ps_car_07_cat      3   cat   \n",
       "28   ps_car_08_cat      2   cat   \n",
       "29   ps_car_09_cat      6   cat   \n",
       "30   ps_car_10_cat      3   cat   \n",
       "31   ps_car_11_cat    104   cat   \n",
       "32       ps_car_11      5  None   \n",
       "33       ps_car_12    132  None   \n",
       "34       ps_car_13  26545  None   \n",
       "35       ps_car_14    731  None   \n",
       "36       ps_car_15     15  None   \n",
       "37      ps_calc_01     10  calc   \n",
       "38      ps_calc_02     10  calc   \n",
       "39      ps_calc_03     10  calc   \n",
       "40      ps_calc_04      6  calc   \n",
       "41      ps_calc_05      7  calc   \n",
       "42      ps_calc_06     10  calc   \n",
       "43      ps_calc_07     10  calc   \n",
       "44      ps_calc_08     11  calc   \n",
       "45      ps_calc_09      8  calc   \n",
       "46      ps_calc_10     24  calc   \n",
       "47      ps_calc_11     17  calc   \n",
       "48      ps_calc_12      9  calc   \n",
       "49      ps_calc_13     14  calc   \n",
       "50      ps_calc_14     23  calc   \n",
       "51  ps_calc_15_bin      2   bin   \n",
       "52  ps_calc_16_bin      2   bin   \n",
       "53  ps_calc_17_bin      2   bin   \n",
       "54  ps_calc_18_bin      2   bin   \n",
       "55  ps_calc_19_bin      2   bin   \n",
       "56  ps_calc_20_bin      2   bin   \n",
       "\n",
       "                                              first_5  \n",
       "0                                     [0, 1, 2, 3, 4]  \n",
       "1                                    [1, 2, 3, 4, -1]  \n",
       "2                                     [0, 1, 2, 3, 4]  \n",
       "3                                          [0, 1, -1]  \n",
       "4                                     [0, 1, 2, 3, 4]  \n",
       "5                                              [0, 1]  \n",
       "6                                              [0, 1]  \n",
       "7                                              [0, 1]  \n",
       "8                                              [0, 1]  \n",
       "9                                              [0, 1]  \n",
       "10                                             [0, 1]  \n",
       "11                                             [0, 1]  \n",
       "12                                             [0, 1]  \n",
       "13                                    [0, 1, 2, 3, 4]  \n",
       "14                                    [0, 1, 2, 3, 4]  \n",
       "15                                             [0, 1]  \n",
       "16                                             [0, 1]  \n",
       "17                                             [0, 1]  \n",
       "18                          [0.6, 0.8, 0.1, 0.7, 0.4]  \n",
       "19                          [0.3, 0.0, 0.6, 0.2, 0.4]  \n",
       "20  [0.5, 1.8585948994, 1.1241663578, 1.4899664426...  \n",
       "21                                    [0, 1, 2, 3, 4]  \n",
       "22                                             [0, 1]  \n",
       "23                                         [0, 1, -1]  \n",
       "24                                    [0, 1, 2, 3, 4]  \n",
       "25                                         [0, 1, -1]  \n",
       "26                                    [0, 1, 2, 3, 4]  \n",
       "27                                         [0, 1, -1]  \n",
       "28                                             [0, 1]  \n",
       "29                                    [0, 1, 2, 3, 4]  \n",
       "30                                          [0, 1, 2]  \n",
       "31                                    [1, 2, 3, 4, 5]  \n",
       "32                                   [0, 1, 2, 3, -1]  \n",
       "33  [0.5291502621999999, 0.3155946768, 0.5, 0.3160...  \n",
       "34  [0.7492282531000001, 1.3741714258000002, 1.584...  \n",
       "35  [0.4062019202, 0.4283689998, 0.320468407199999...  \n",
       "36  [0.0, 1.0, 2.6457513111, 3.6055512755, 2.44948...  \n",
       "37                          [0.9, 0.6, 0.3, 0.2, 0.5]  \n",
       "38                          [0.6, 0.4, 0.1, 0.8, 0.3]  \n",
       "39                          [0.6, 0.0, 0.1, 0.3, 0.9]  \n",
       "40                                    [0, 1, 2, 3, 4]  \n",
       "41                                    [0, 1, 2, 3, 4]  \n",
       "42                                    [1, 2, 3, 4, 5]  \n",
       "43                                    [0, 1, 2, 3, 4]  \n",
       "44                                    [2, 3, 4, 5, 6]  \n",
       "45                                    [0, 1, 2, 3, 4]  \n",
       "46                                    [0, 1, 2, 3, 4]  \n",
       "47                                    [0, 1, 2, 3, 4]  \n",
       "48                                    [0, 1, 2, 3, 4]  \n",
       "49                                    [0, 1, 2, 3, 4]  \n",
       "50                                    [0, 1, 2, 3, 4]  \n",
       "51                                             [0, 1]  \n",
       "52                                             [0, 1]  \n",
       "53                                             [0, 1]  \n",
       "54                                             [0, 1]  \n",
       "55                                             [0, 1]  \n",
       "56                                             [0, 1]  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls = []\n",
    "for i in X_train.columns:\n",
    "    \n",
    "    num_un = X_train[i].nunique()\n",
    "    ls_un = list(set(X_train[i]))[:5]\n",
    "    \n",
    "    if 'cat' in i:\n",
    "        ls.append([i, num_un,'cat', ls_un])\n",
    "    elif 'bin' in i:\n",
    "        ls.append([i, num_un,'bin', ls_un])\n",
    "    elif 'ind' in i:\n",
    "        ls.append([i, num_un,'ind', ls_un])\n",
    "    elif 'calc' in i:\n",
    "        ls.append([i, num_un,'calc', ls_un])\n",
    "    else:\n",
    "        ls.append([i, num_un,None, ls_un])\n",
    "    \n",
    "ls = pd.DataFrame(ls)\n",
    "ls.columns = ['col','nuniq','d_tp','first_5']\n",
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ind', 'cat', 'bin', None, 'calc'], dtype=object)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls.d_tp.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ps_ind_02_cat',\n",
       " 'ps_ind_04_cat',\n",
       " 'ps_ind_05_cat',\n",
       " 'ps_car_01_cat',\n",
       " 'ps_car_02_cat',\n",
       " 'ps_car_03_cat',\n",
       " 'ps_car_04_cat',\n",
       " 'ps_car_05_cat',\n",
       " 'ps_car_06_cat',\n",
       " 'ps_car_07_cat',\n",
       " 'ps_car_08_cat',\n",
       " 'ps_car_09_cat',\n",
       " 'ps_car_10_cat',\n",
       " 'ps_car_11_cat']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ls[ls.d_tp == 'cat'].col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col</th>\n",
       "      <th>nuniq</th>\n",
       "      <th>d_tp</th>\n",
       "      <th>first_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ps_reg_01</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>[0.6, 0.8, 0.1, 0.7, 0.4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ps_reg_02</td>\n",
       "      <td>19</td>\n",
       "      <td>None</td>\n",
       "      <td>[0.3, 0.0, 0.6, 0.2, 0.4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ps_reg_03</td>\n",
       "      <td>4399</td>\n",
       "      <td>None</td>\n",
       "      <td>[0.5, 1.8585948994, 1.1241663578, 1.4899664426...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ps_car_11</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>[0, 1, 2, 3, -1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>ps_car_12</td>\n",
       "      <td>132</td>\n",
       "      <td>None</td>\n",
       "      <td>[0.5291502621999999, 0.3155946768, 0.5, 0.3160...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>ps_car_13</td>\n",
       "      <td>26545</td>\n",
       "      <td>None</td>\n",
       "      <td>[0.7492282531000001, 1.3741714258000002, 1.584...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>ps_car_14</td>\n",
       "      <td>731</td>\n",
       "      <td>None</td>\n",
       "      <td>[0.4062019202, 0.4283689998, 0.320468407199999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>ps_car_15</td>\n",
       "      <td>15</td>\n",
       "      <td>None</td>\n",
       "      <td>[0.0, 1.0, 2.6457513111, 3.6055512755, 2.44948...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          col  nuniq  d_tp                                            first_5\n",
       "18  ps_reg_01     10  None                          [0.6, 0.8, 0.1, 0.7, 0.4]\n",
       "19  ps_reg_02     19  None                          [0.3, 0.0, 0.6, 0.2, 0.4]\n",
       "20  ps_reg_03   4399  None  [0.5, 1.8585948994, 1.1241663578, 1.4899664426...\n",
       "32  ps_car_11      5  None                                   [0, 1, 2, 3, -1]\n",
       "33  ps_car_12    132  None  [0.5291502621999999, 0.3155946768, 0.5, 0.3160...\n",
       "34  ps_car_13  26545  None  [0.7492282531000001, 1.3741714258000002, 1.584...\n",
       "35  ps_car_14    731  None  [0.4062019202, 0.4283689998, 0.320468407199999...\n",
       "36  ps_car_15     15  None  [0.0, 1.0, 2.6457513111, 3.6055512755, 2.44948..."
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls[ls.d_tp.isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <font color='purple'>В задании нет описания признаков, поэтому определим, что:    \n",
    "> <font color='purple'>* ind - числовые,    \n",
    "> <font color='purple'>* bin - булевые(бинарные),    \n",
    "> <font color='purple'>* None - вещественные,    \n",
    "> <font color='purple'>* Calc - числовые/вещественные    \n",
    "\n",
    "> <font color='purple'>А вот cat - это категориальные признаки, будем брать только их для целей кодирования</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!pip install category_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from category_encoders.one_hot import OneHotEncoder\n",
    "\n",
    "X_train_cat = list(ls[ls.d_tp == 'cat'].col)\n",
    "\n",
    "one_hot_enc = OneHotEncoder(cols = X_train_cat)\n",
    "\n",
    "X_train_encoded = one_hot_enc.fit_transform(X_train)\n",
    "X_test_encoded = one_hot_enc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5782\n",
      "ROC_AUC: 0.6098561979819292\n",
      "CPU times: total: 5min 10s\n",
      "Wall time: 26.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_train_encoded, y_train)\n",
    "\n",
    "prediction = lr.predict(X_test_encoded)\n",
    "probs = lr.predict_proba(X_test_encoded)\n",
    "\n",
    "print(f'''Accuracy: {accuracy_score(y_test, prediction)}\n",
    "ROC_AUC: {roc_auc_score(y_test, probs[:,1])}''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <font color='purple'>**Результат:** здесь видно интересный момент, хоть наша модель и считает немного хуже, но работает гораздо быстрее</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как можно было заменить, one-hot-кодирование сильно увилечивает количество признаков в датасете, что сказывается на памяти, особенно, если некоторый признак имеет большое количество значений. Эту проблему решает другой способ кодирование категориальных признаков — счётчики. Основная идея в том, что нам важны не сами категории, а значения целевой переменной, которые имеют объекты этой категории. Каждый категориальный признак мы заменим средним значением целевой переменной по всем объектам этой же категории:\n",
    "$$\n",
    "g_j(x, X) = \\frac{\\sum_{i=1}^{l} [f_j(x) = f_j(x_i)][y_i = +1]}{\\sum_{i=1}^{l} [f_j(x) = f_j(x_i)]}\n",
    "$$\n",
    "\n",
    "__Задание 7 (1.5 балла).__ Закодируйте категориальные переменные с помощью счётчиков (ровно так, как описано выше, без каких-либо хитростей). Обучите логистическую регрессию и посмотрите на качество модели на тестовом множестве. Сравните время обучения с предыдущим экспериментом. Заметили ли вы что-то интересное?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ps_ind_01</th>\n",
       "      <th>ps_ind_02_cat</th>\n",
       "      <th>ps_ind_03</th>\n",
       "      <th>ps_ind_04_cat</th>\n",
       "      <th>ps_ind_05_cat</th>\n",
       "      <th>ps_ind_06_bin</th>\n",
       "      <th>ps_ind_07_bin</th>\n",
       "      <th>ps_ind_08_bin</th>\n",
       "      <th>ps_ind_09_bin</th>\n",
       "      <th>ps_ind_10_bin</th>\n",
       "      <th>...</th>\n",
       "      <th>ps_calc_11</th>\n",
       "      <th>ps_calc_12</th>\n",
       "      <th>ps_calc_13</th>\n",
       "      <th>ps_calc_14</th>\n",
       "      <th>ps_calc_15_bin</th>\n",
       "      <th>ps_calc_16_bin</th>\n",
       "      <th>ps_calc_17_bin</th>\n",
       "      <th>ps_calc_18_bin</th>\n",
       "      <th>ps_calc_19_bin</th>\n",
       "      <th>ps_calc_20_bin</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1049183</th>\n",
       "      <td>0</td>\n",
       "      <td>0.495424</td>\n",
       "      <td>5</td>\n",
       "      <td>0.486512</td>\n",
       "      <td>0.479374</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106872</th>\n",
       "      <td>1</td>\n",
       "      <td>0.495424</td>\n",
       "      <td>3</td>\n",
       "      <td>0.516808</td>\n",
       "      <td>0.479374</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28943</th>\n",
       "      <td>6</td>\n",
       "      <td>0.508632</td>\n",
       "      <td>7</td>\n",
       "      <td>0.516808</td>\n",
       "      <td>0.479374</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>851826</th>\n",
       "      <td>1</td>\n",
       "      <td>0.495424</td>\n",
       "      <td>5</td>\n",
       "      <td>0.516808</td>\n",
       "      <td>0.479374</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934813</th>\n",
       "      <td>0</td>\n",
       "      <td>0.495424</td>\n",
       "      <td>1</td>\n",
       "      <td>0.486512</td>\n",
       "      <td>0.611746</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624097</th>\n",
       "      <td>3</td>\n",
       "      <td>0.495424</td>\n",
       "      <td>5</td>\n",
       "      <td>0.486512</td>\n",
       "      <td>0.479374</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697975</th>\n",
       "      <td>0</td>\n",
       "      <td>0.508632</td>\n",
       "      <td>1</td>\n",
       "      <td>0.516808</td>\n",
       "      <td>0.479374</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723907</th>\n",
       "      <td>5</td>\n",
       "      <td>0.495424</td>\n",
       "      <td>3</td>\n",
       "      <td>0.516808</td>\n",
       "      <td>0.479374</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1055788</th>\n",
       "      <td>0</td>\n",
       "      <td>0.495424</td>\n",
       "      <td>3</td>\n",
       "      <td>0.486512</td>\n",
       "      <td>0.479374</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072907</th>\n",
       "      <td>2</td>\n",
       "      <td>0.495424</td>\n",
       "      <td>3</td>\n",
       "      <td>0.516808</td>\n",
       "      <td>0.479374</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ps_ind_01  ps_ind_02_cat  ps_ind_03  ps_ind_04_cat  ps_ind_05_cat  \\\n",
       "id                                                                           \n",
       "1049183          0       0.495424          5       0.486512       0.479374   \n",
       "106872           1       0.495424          3       0.516808       0.479374   \n",
       "28943            6       0.508632          7       0.516808       0.479374   \n",
       "851826           1       0.495424          5       0.516808       0.479374   \n",
       "934813           0       0.495424          1       0.486512       0.611746   \n",
       "...            ...            ...        ...            ...            ...   \n",
       "624097           3       0.495424          5       0.486512       0.479374   \n",
       "697975           0       0.508632          1       0.516808       0.479374   \n",
       "723907           5       0.495424          3       0.516808       0.479374   \n",
       "1055788          0       0.495424          3       0.486512       0.479374   \n",
       "1072907          2       0.495424          3       0.516808       0.479374   \n",
       "\n",
       "         ps_ind_06_bin  ps_ind_07_bin  ps_ind_08_bin  ps_ind_09_bin  \\\n",
       "id                                                                    \n",
       "1049183              1              0              0              0   \n",
       "106872               0              1              0              0   \n",
       "28943                0              0              1              0   \n",
       "851826               0              0              1              0   \n",
       "934813               1              0              0              0   \n",
       "...                ...            ...            ...            ...   \n",
       "624097               0              1              0              0   \n",
       "697975               1              0              0              0   \n",
       "723907               0              1              0              0   \n",
       "1055788              1              0              0              0   \n",
       "1072907              0              1              0              0   \n",
       "\n",
       "         ps_ind_10_bin  ...  ps_calc_11  ps_calc_12  ps_calc_13  ps_calc_14  \\\n",
       "id                      ...                                                   \n",
       "1049183              0  ...           4           3           4           6   \n",
       "106872               0  ...           9           0           4          12   \n",
       "28943                0  ...           4           1           2           7   \n",
       "851826               0  ...           6           2           2          10   \n",
       "934813               0  ...           9           1           2          14   \n",
       "...                ...  ...         ...         ...         ...         ...   \n",
       "624097               0  ...           9           1           0           5   \n",
       "697975               0  ...           6           0           2           7   \n",
       "723907               0  ...           6           2           1           7   \n",
       "1055788              0  ...           6           2           4           7   \n",
       "1072907              0  ...           3           3           0          12   \n",
       "\n",
       "         ps_calc_15_bin  ps_calc_16_bin  ps_calc_17_bin  ps_calc_18_bin  \\\n",
       "id                                                                        \n",
       "1049183               0               0               0               0   \n",
       "106872                0               1               1               0   \n",
       "28943                 0               1               1               0   \n",
       "851826                0               0               1               0   \n",
       "934813                0               1               1               0   \n",
       "...                 ...             ...             ...             ...   \n",
       "624097                1               1               1               0   \n",
       "697975                0               1               0               0   \n",
       "723907                0               0               0               1   \n",
       "1055788               1               1               1               1   \n",
       "1072907               0               1               0               0   \n",
       "\n",
       "         ps_calc_19_bin  ps_calc_20_bin  \n",
       "id                                       \n",
       "1049183               0               0  \n",
       "106872                0               0  \n",
       "28943                 1               0  \n",
       "851826                0               0  \n",
       "934813                0               0  \n",
       "...                 ...             ...  \n",
       "624097                1               0  \n",
       "697975                1               0  \n",
       "723907                0               0  \n",
       "1055788               0               0  \n",
       "1072907               0               0  \n",
       "\n",
       "[100000 rows x 57 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def encode_plus(X,y,col):\n",
    "    df = X.assign(target = y)\n",
    "    for i in col:\n",
    "        df[i] = df[[i,'target']].groupby([i]).transform('mean')\n",
    "    df = df.drop('target', axis=1)    \n",
    "    return df\n",
    "\n",
    "\n",
    "ls_cat_col = list(ls[ls.d_tp == 'cat'].col)\n",
    "X_train_encode_plus = encode_plus(X_train,y_train,ls_cat_col)\n",
    "X_train_encode_plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5935\n",
      "ROC_AUC: 0.6098561979819292\n",
      "CPU times: total: 43.1 s\n",
      "Wall time: 10 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_train_encode_plus, y_train)\n",
    "\n",
    "X_test_encode_plus = encode_plus(X_test,y_test,ls_cat_col)\n",
    "\n",
    "prediction = lr.predict(X_test_encode_plus)\n",
    "probs_test = lr.predict_proba(X_test_encode_plus)[:,1]\n",
    "\n",
    "print(f'''Accuracy: {accuracy_score(y_test, prediction)}\n",
    "ROC_AUC: {roc_auc_score(y_test, probs[:,1])}''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <font color='purple'>AUC_ROC немного улучшился, но модель стала гораздо быстрее обучаться.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отметим, что такие признаки сами по себе являются классификаторами и, обучаясь на них, мы допускаем \"утечку\" целевой переменной в признаки. Это ведёт к переобучению, поэтому считать такие признаки необходимо так, чтобы при вычислении для конкретного объекта его целевая метка не использовалась. Это можно делать следующими способами:\n",
    "1. Вычислять значение счётчика по всем объектам расположенным выше в датасете (например, если у нас выборка отсортирована по времени).\n",
    "2. Вычислять по фолдам, то есть делить выборку на некоторое количество частей и подсчитывать значение признаков по всем фолдам кроме текущего (как делается в кросс-валидации).\n",
    "3. Внесение некоторого шума в посчитанные признаки. \n",
    "\n",
    "__Задание 8 (1 балл)__. Реализуйте корректное вычисление счётчиков самым простым способом — добавление шума к значениям (необходимо соблюсти баланс между избавление от переобучения и полезностью признаков). Снова обучите логистическую регрессию, оцените качество. Сделайте выводы.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_plus_noise(X,y,col,noise):\n",
    "    df = X.assign(target = y)\n",
    "    for i in col:\n",
    "        df[i] = df[[i,'target']].groupby([i]).transform('mean')\n",
    "        df[i] = df[i]+ np.random.uniform(0, noise)\n",
    "    df = df.drop('target', axis=1)    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.58902\n",
      "ROC_AUC: 0.6098561979819292\n",
      "CPU times: total: 3.89 s\n",
      "Wall time: 1.88 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "q_noise = 0.0001\n",
    "ls_cat_col = list(ls[ls.d_tp == 'cat'].col)\n",
    "X_train_encode_plus_noise = encode_plus_noise(X_train, y_train, ls_cat_col, q_noise)\n",
    "X_test_encode_plus_noise = encode_plus_noise(X_test, y_test, ls_cat_col, q_noise)\n",
    "\n",
    "lr = LogisticRegression(max_iter=100)\n",
    "lr.fit(X_train_encode_plus_noise, y_train)\n",
    "\n",
    "prediction = lr.predict(X_test_encode_plus_noise)\n",
    "probs_test = lr.predict_proba(X_test_encode_plus_noise)[:,1]\n",
    "\n",
    "print(f'''Accuracy: {accuracy_score(y_test, prediction)}\n",
    "ROC_AUC: {roc_auc_score(y_test, probs[:,1])}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.58486\n",
      "ROC_AUC: 0.6098561979819292\n",
      "CPU times: total: 3.62 s\n",
      "Wall time: 1.89 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "q_noise = 0.01\n",
    "ls_cat_col = list(ls[ls.d_tp == 'cat'].col)\n",
    "X_train_encode_plus_noise = encode_plus_noise(X_train, y_train, ls_cat_col, q_noise)\n",
    "X_test_encode_plus_noise = encode_plus_noise(X_test, y_test, ls_cat_col, q_noise)\n",
    "\n",
    "lr = LogisticRegression(max_iter=100)\n",
    "lr.fit(X_train_encode_plus_noise, y_train)\n",
    "\n",
    "prediction = lr.predict(X_test_encode_plus_noise)\n",
    "probs_test = lr.predict_proba(X_test_encode_plus_noise)[:,1]\n",
    "\n",
    "print(f'''Accuracy: {accuracy_score(y_test, prediction)}\n",
    "ROC_AUC: {roc_auc_score(y_test, probs[:,1])}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.58239\n",
      "ROC_AUC: 0.6098561979819292\n",
      "CPU times: total: 6.91 s\n",
      "Wall time: 1.91 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "q_noise = 1\n",
    "ls_cat_col = list(ls[ls.d_tp == 'cat'].col)\n",
    "X_train_encode_plus_noise = encode_plus_noise(X_train, y_train, ls_cat_col, q_noise)\n",
    "X_test_encode_plus_noise = encode_plus_noise(X_test, y_test, ls_cat_col, q_noise)\n",
    "\n",
    "lr = LogisticRegression(max_iter=100)\n",
    "lr.fit(X_train_encode_plus_noise, y_train)\n",
    "\n",
    "prediction = lr.predict(X_test_encode_plus_noise)\n",
    "probs_test = lr.predict_proba(X_test_encode_plus_noise)[:,1]\n",
    "\n",
    "print(f'''Accuracy: {accuracy_score(y_test, prediction)}\n",
    "ROC_AUC: {roc_auc_score(y_test, probs[:,1])}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.50006\n",
      "ROC_AUC: 0.6098561979819292\n",
      "CPU times: total: 5.98 s\n",
      "Wall time: 1.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "q_noise = 10\n",
    "ls_cat_col = list(ls[ls.d_tp == 'cat'].col)\n",
    "X_train_encode_plus_noise = encode_plus_noise(X_train, y_train, ls_cat_col, q_noise)\n",
    "X_test_encode_plus_noise = encode_plus_noise(X_test, y_test, ls_cat_col, q_noise)\n",
    "\n",
    "lr = LogisticRegression(max_iter=100)\n",
    "lr.fit(X_train_encode_plus_noise, y_train)\n",
    "\n",
    "prediction = lr.predict(X_test_encode_plus_noise)\n",
    "probs_test = lr.predict_proba(X_test_encode_plus_noise)[:,1]\n",
    "\n",
    "print(f'''Accuracy: {accuracy_score(y_test, prediction)}\n",
    "ROC_AUC: {roc_auc_score(y_test, probs[:,1])}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.49994\n",
      "ROC_AUC: 0.6098561979819292\n",
      "CPU times: total: 1.02 s\n",
      "Wall time: 962 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "q_noise = 100000\n",
    "ls_cat_col = list(ls[ls.d_tp == 'cat'].col)\n",
    "X_train_encode_plus_noise = encode_plus_noise(X_train, y_train, ls_cat_col, q_noise)\n",
    "X_test_encode_plus_noise = encode_plus_noise(X_test, y_test, ls_cat_col, q_noise)\n",
    "\n",
    "lr = LogisticRegression(max_iter=100)\n",
    "lr.fit(X_train_encode_plus_noise, y_train)\n",
    "\n",
    "prediction = lr.predict(X_test_encode_plus_noise)\n",
    "probs_test = lr.predict_proba(X_test_encode_plus_noise)[:,1]\n",
    "\n",
    "print(f'''Accuracy: {accuracy_score(y_test, prediction)}\n",
    "ROC_AUC: {roc_auc_score(y_test, probs[:,1])}''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <font color='purple'>**Результат:** постарался сделать шум, но при изменении коэффециента шума не увидел сильных отличий по ROC-AUC, возможно что-то не так реализовал, не могу понять</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 3. Отбор признаков (3 балла + 1 бонус)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Важной частью процесса построения модели является отбор признаков. На практике многие признаки оказывают малое влияние на модель (при этом они увеличивают время вычислений) или даже негативно сказываются на качестве модели. Попробуем несколько подходов отбора признаков, оценим, как они влияют на качество модели и сколько времени занимают.\n",
    "\n",
    "Обратимся к тому же датасету про обращение клиентов по страховым случаям. Обойдёмся без сэмплирования объектов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-12T07:36:04.765536Z",
     "start_time": "2018-10-12T07:35:57.814973Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv', index_col=0)\n",
    "target = data.target.values\n",
    "data = data.drop('target', axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=124)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как вы помните, в данных много категориальных признаков. Давайте закодируем их с помощью one-hot кодирования. Исходные колонки с категориальными признаками можно удалить. Сколько признаков мы получили?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(476169, 227)\n",
      "(119043, 227)\n"
     ]
    }
   ],
   "source": [
    "from category_encoders.one_hot import OneHotEncoder\n",
    "\n",
    "X_train_cat = list(ls[ls.d_tp == 'cat'].col)\n",
    "\n",
    "one_hot_enc = OneHotEncoder(cols = X_train_cat)\n",
    "\n",
    "X_train_encoded = one_hot_enc.fit_transform(X_train)\n",
    "X_test_encoded = one_hot_enc.fit_transform(X_test)\n",
    "\n",
    "print(X_train_encoded.shape)\n",
    "print(X_test_encoded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <font color='purple'>Получилось 227 столбцов</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве основной модели будем использовать логистическую регрессию, а целевой метрики — ROC-AUC. Обучите модель и посчитайте качество на тестовой выборке. Давайте запомним полученное значение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9637021916450358\n",
      "ROC_AUC: 0.5943036316187646\n",
      "CPU times: total: 19min 54s\n",
      "Wall time: 1min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_train_encoded, y_train)\n",
    "\n",
    "prediction = lr.predict(X_test_encoded)\n",
    "probs = lr.predict_proba(X_test_encoded)\n",
    "\n",
    "print(f'''Accuracy: {accuracy_score(y_test, prediction)}\n",
    "ROC_AUC: {roc_auc_score(y_test, probs[:,1])}''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <font color='purple'>**Результат:** при таком высоком Accuracy и низком ROC_AUC становится понятно что классы несбалансированные</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Встроенные методы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Допустим, мы хотим оставить только 200 лучших признаков. Попробуем сделать это несколькими способами.\n",
    "\n",
    "Начнём с отборам признаков с помощью линейной модели. Как известно, веса линейной модели означают вклад каждого признака в предсказание модели, а значит, модуль этого вклада можно интерпретировать как важность признаков. Такой метод отбора называются встроенным или embedded methods, так как он заложен в особенности модели.\n",
    "\n",
    "__Задание 10 (1 балл).__ Оставьте 200 признаков с наибольшим модулем соответсвующего параметра линейной модели. Обучите модели заново и оцените её качество. Замерьте скорость такого отбора признаков.\n",
    "\n",
    "Изменилось ли качество? Как?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_feat</th>\n",
       "      <th>value_feat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ps_ind_01</td>\n",
       "      <td>0.008773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ps_ind_02_cat_1</td>\n",
       "      <td>0.289570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ps_ind_02_cat_2</td>\n",
       "      <td>0.174665</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         name_feat  value_feat\n",
       "0        ps_ind_01    0.008773\n",
       "1  ps_ind_02_cat_1    0.289570\n",
       "2  ps_ind_02_cat_2    0.174665"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls_feat = []\n",
    "for i in range(lr.coef_.shape[1]):\n",
    "    ls_feat.append([lr.feature_names_in_[i],abs(lr.coef_[0][i])])\n",
    "    \n",
    "dict_feat = pd.DataFrame(ls_feat, columns = ['name_feat', 'value_feat'])\n",
    "dict_feat.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_columns = dict_feat.sort_values(by='value_feat', ascending = False).head(200).name_feat.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9637021916450358\n",
      "ROC_AUC: 0.5948314523493096\n",
      "CPU times: total: 8min 6s\n",
      "Wall time: 46.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_train_encoded[new_columns], y_train)\n",
    "\n",
    "prediction = lr.predict(X_test_encoded[new_columns])\n",
    "probs = lr.predict_proba(X_test_encoded[new_columns])\n",
    "\n",
    "print(f'''Accuracy: {accuracy_score(y_test, prediction)}\n",
    "ROC_AUC: {roc_auc_score(y_test, probs[:,1])}''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <font color='purple'>**Результат:** качество не изменилось, но модель стала быстрее обучаться</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь давайте подумаем, что мы не учли. Мы предположили, что признаки вносят вклад равномерно, но не учли их масштаба. Если мы умножим один из признаков в 100 раз, то без учёта регуляризации его вес уменьшится в эти же 100 раз. А мы на основе этого отбираем признаки! Давайте сначала отнормируем признаки одним из способов, а только потом будем удалять признаки. \n",
    "\n",
    "Кстати, в таком случае надо пересчитать качество на всех признаках (сделайте это ниже). Если вы сделали нормирование признаков в самом начале, то попробуйте отобрать признаки на неотмасштабированных данных.\n",
    "\n",
    "Что получилось?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled_features = scaler.fit_transform(X_train)\n",
    "X_test_scaled_features = scaler.fit_transform(X_test)\n",
    "\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled_features, columns=X_train.columns)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled_features, columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9637021916450358\n",
      "ROC_AUC: 0.6276338158229305\n",
      "CPU times: total: 4.97 s\n",
      "Wall time: 1.23 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "prediction = lr.predict(X_test_scaled)\n",
    "probs = lr.predict_proba(X_test_scaled)\n",
    "\n",
    "print(f'''Accuracy: {accuracy_score(y_test, prediction)}\n",
    "ROC_AUC: {roc_auc_score(y_test, probs[:,1])}''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <font color='purple'>при нормировании качество ROC-AUC немного улучшилось</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_feat = []\n",
    "for i in range(lr.coef_.shape[1]):\n",
    "    ls_feat.append([lr.feature_names_in_[i],abs(lr.coef_[0][i])])\n",
    "    \n",
    "dict_feat = pd.DataFrame(ls_feat, columns = ['name_feat', 'value_feat'])\n",
    "new_columns = dict_feat.sort_values(by='value_feat', ascending = False).head(200).name_feat.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9637021916450358\n",
      "ROC_AUC: 0.6276338158229305\n",
      "CPU times: total: 6.91 s\n",
      "Wall time: 1.33 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_train_scaled[new_columns], y_train)\n",
    "\n",
    "prediction = lr.predict(X_test_scaled[new_columns])\n",
    "probs = lr.predict_proba(X_test_scaled[new_columns])\n",
    "\n",
    "print(f'''Accuracy: {accuracy_score(y_test, prediction)}\n",
    "ROC_AUC: {roc_auc_score(y_test, probs[:,1])}''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <font color='purple'>**Результат:** если оставить только 200 наиболее значимых признаков после нормирования результат не меняется</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 10 (0.5 балла).__\n",
    "Можно задать отбор признаков более функционально. Вспомним, что L1-регуляризация также умеет отбирать признаки. Понятно, что теперь нам будет сложнее оставить именно 200 лучших признаков, но возможно они нам и не нужны. Подберите коэффициент регуляризации и проверьте, как изменилось качество. Получилось ли добиться лучшего качества при менее чем 200 признаках?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9637021916450358\n",
      "ROC_AUC: 0.6276319195673249\n",
      "CPU times: total: 5.48 s\n",
      "Wall time: 5.44 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "lr = LogisticRegression(penalty='l1',solver = 'liblinear', C=100.0)\n",
    "lr.fit(X_train_scaled[new_columns], y_train)\n",
    "\n",
    "prediction = lr.predict(X_test_scaled[new_columns])\n",
    "probs = lr.predict_proba(X_test_scaled[new_columns])\n",
    "\n",
    "print(f'''Accuracy: {accuracy_score(y_test, prediction)}\n",
    "ROC_AUC: {roc_auc_score(y_test, probs[:,1])}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оптимальное значение коэффициента регуляризации:\" 99999.99999999999\n",
      "Accuracy: 0.9637021916450358\n",
      "ROC_AUC: 0.6276333357071495\n",
      "CPU times: total: 3min 1s\n",
      "Wall time: 51 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Создание модели логистической регрессии\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Задание диапазона значений коэффициента регуляризации\n",
    "param_grid = {'C': [1 / 10**i for i in range(-5, 6)]}  # Пример диапазона от 0.001 до 1000\n",
    "\n",
    "# Подбор коэффициента регуляризации с помощью кросс-валидации\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5)\n",
    "grid_search.fit(X_train_scaled[new_columns], y_train) \n",
    "\n",
    "prediction = grid_search.predict(X_test_scaled[new_columns])\n",
    "probs = grid_search.predict_proba(X_test_scaled[new_columns])\n",
    "\n",
    "\n",
    "\n",
    "# Вывод оптимального значения коэффициента регуляризации\n",
    "print(f'''Оптимальное значение коэффициента регуляризации:\" {grid_search.best_params_['C']}\n",
    "Accuracy: {accuracy_score(y_test, prediction)}\n",
    "ROC_AUC: {roc_auc_score(y_test, probs[:,1])}''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <font color='purple'>**Результат:** Какие только коэффициенты не пробовал, ROC-AUC выше 0.627 не поднимается</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Методы фильтрации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте отбирать признаки умнее, а именно через подсчёт некоторой функции для каждого признака. На основании значений этой функции будем оставлять наиболее важные признаки. Методы этого семейства называют фильтрующими или  filter methods. \n",
    "\n",
    "В качестве такой функции будем считать t-статистику:\n",
    "\n",
    "$$t(x) = \\frac{|\\mu_+ - \\mu_-|}{\\sqrt{\\frac{n_+ \\sigma^2_+ + n_- \\sigma^2_-}{n_+ + n_-}}},$$\n",
    "\n",
    "где $mu$, $sigma$, $n$ соответственно среднее, среднеквадратичное отклонение и количество объектов каждого из классов.\n",
    "\n",
    "Если у вас был курс математической статистики, то вы без труда узнаете статистику гипотезы о разности средних при неизвестных дисперсиях. Если же нет, то интуиция следующая. Вообще мы хотим понять, различаются ли распределения признака для двух разных классов. Мы проверяем, что математические ожидания двух распределений различаются. Если они различаются, значит и сами распределения разные. Отсюда можно сделать вывод, что по этому признаку модель сможет отличить один класс от другого. А если распределения неотличимы и статистика маленькая, то и признак бесполезен. \n",
    "\n",
    "Важно оговориться, что хотя мы и не используем статистическое тестирование явно, предпосылки о том, что наблюдения независимы, одинаково распределены и n велико, должны соблюдаться, иначе статистика не имеет смысла. Но у нас большая выборка, поэтому они выполняются. По-хорошему, конечно, надо бы сравнивать статистику с пороговым значением t-распределения и полноценно тестировать гипотезу, но мы обойдёмся простой эвристикой и возьмём признаки с наибольшим значением.\n",
    "\n",
    "\n",
    "__Задание 11 (1 балл)__. Оставьте 200 признаков с наибольшим значением и замерьте качество. Не забудьте замерить скорость отбора признаков в этом случаев."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ps_ind_01</th>\n",
       "      <th>ps_ind_02_cat</th>\n",
       "      <th>ps_ind_03</th>\n",
       "      <th>ps_ind_04_cat</th>\n",
       "      <th>ps_ind_05_cat</th>\n",
       "      <th>ps_ind_06_bin</th>\n",
       "      <th>ps_ind_07_bin</th>\n",
       "      <th>ps_ind_08_bin</th>\n",
       "      <th>ps_ind_09_bin</th>\n",
       "      <th>ps_ind_10_bin</th>\n",
       "      <th>...</th>\n",
       "      <th>ps_calc_11</th>\n",
       "      <th>ps_calc_12</th>\n",
       "      <th>ps_calc_13</th>\n",
       "      <th>ps_calc_14</th>\n",
       "      <th>ps_calc_15_bin</th>\n",
       "      <th>ps_calc_16_bin</th>\n",
       "      <th>ps_calc_17_bin</th>\n",
       "      <th>ps_calc_18_bin</th>\n",
       "      <th>ps_calc_19_bin</th>\n",
       "      <th>ps_calc_20_bin</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>381341</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1327969</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601794</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632925</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74864</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1215796</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514147</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182212</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258042</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1158078</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>476169 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ps_ind_01  ps_ind_02_cat  ps_ind_03  ps_ind_04_cat  ps_ind_05_cat  \\\n",
       "id                                                                           \n",
       "381341           1              1          8              0              0   \n",
       "1327969          2              2          2              1              0   \n",
       "601794           0              1          2              0              0   \n",
       "632925           6              1         11              1              0   \n",
       "74864            3              1          5              1              0   \n",
       "...            ...            ...        ...            ...            ...   \n",
       "1215796          2              1          6              1              0   \n",
       "514147           1              1          7              1              0   \n",
       "1182212          3              2          4              1              0   \n",
       "258042           3              1          1              1              0   \n",
       "1158078          1              2          0              1              4   \n",
       "\n",
       "         ps_ind_06_bin  ps_ind_07_bin  ps_ind_08_bin  ps_ind_09_bin  \\\n",
       "id                                                                    \n",
       "381341               0              0              1              0   \n",
       "1327969              0              0              0              1   \n",
       "601794               1              0              0              0   \n",
       "632925               0              1              0              0   \n",
       "74864                0              0              1              0   \n",
       "...                ...            ...            ...            ...   \n",
       "1215796              1              0              0              0   \n",
       "514147               1              0              0              0   \n",
       "1182212              0              0              0              1   \n",
       "258042               0              1              0              0   \n",
       "1158078              0              0              1              0   \n",
       "\n",
       "         ps_ind_10_bin  ...  ps_calc_11  ps_calc_12  ps_calc_13  ps_calc_14  \\\n",
       "id                      ...                                                   \n",
       "381341               0  ...           2           1           5           8   \n",
       "1327969              0  ...           6           0           2           5   \n",
       "601794               0  ...           9           1           5           3   \n",
       "632925               0  ...           8           1           2           4   \n",
       "74864                0  ...           9           2           3           8   \n",
       "...                ...  ...         ...         ...         ...         ...   \n",
       "1215796              0  ...           5           1           3           3   \n",
       "514147               0  ...           5           1           5           5   \n",
       "1182212              0  ...           5           1           3           3   \n",
       "258042               0  ...           9           0           2           7   \n",
       "1158078              0  ...           3           0           7          14   \n",
       "\n",
       "         ps_calc_15_bin  ps_calc_16_bin  ps_calc_17_bin  ps_calc_18_bin  \\\n",
       "id                                                                        \n",
       "381341                0               1               1               0   \n",
       "1327969               0               1               1               0   \n",
       "601794                0               0               0               0   \n",
       "632925                0               1               0               0   \n",
       "74864                 0               1               1               1   \n",
       "...                 ...             ...             ...             ...   \n",
       "1215796               0               0               0               0   \n",
       "514147                0               0               0               0   \n",
       "1182212               0               1               0               1   \n",
       "258042                0               1               0               0   \n",
       "1158078               0               0               1               0   \n",
       "\n",
       "         ps_calc_19_bin  ps_calc_20_bin  \n",
       "id                                       \n",
       "381341                0               0  \n",
       "1327969               1               0  \n",
       "601794                1               1  \n",
       "632925                1               1  \n",
       "74864                 0               0  \n",
       "...                 ...             ...  \n",
       "1215796               0               0  \n",
       "514147                0               0  \n",
       "1182212               0               0  \n",
       "258042                1               0  \n",
       "1158078               0               0  \n",
       "\n",
       "[476169 rows x 57 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_stat_func(X,y):\n",
    "    df = X.assign(target = y)\n",
    "    list_value = []\n",
    "    list_col = []\n",
    "    for i in X.columns:\n",
    "        m_plus = df[df.target == 1][i].mean()\n",
    "        m_minus = df[df.target == 0][i].mean()\n",
    "        \n",
    "        n_plus = len(df[df.target == 1][i])\n",
    "        n_minus = len(df[df.target == 0][i])\n",
    "        \n",
    "        s_plus = sum((df[df.target == 1][i]-m_plus)**2)/(n_plus-1)\n",
    "        s_minus = sum((df[df.target == 0][i]-m_minus)**2)/(n_minus-1)\n",
    "        \n",
    "        t = abs(m_plus-m_minus)/(((s_plus/n_plus)+(m_minus/n_minus))**(0.5))\n",
    "        \n",
    "        list_value.append(t)\n",
    "        list_col.append(i)\n",
    "        \n",
    "        \n",
    "    df_res = pd.DataFrame({'col': list_col, 'val': list_value})\n",
    "    \n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ps_ind_02_cat',\n",
       " 'ps_ind_04_cat',\n",
       " 'ps_ind_05_cat',\n",
       " 'ps_car_01_cat',\n",
       " 'ps_car_02_cat',\n",
       " 'ps_car_03_cat',\n",
       " 'ps_car_04_cat',\n",
       " 'ps_car_05_cat',\n",
       " 'ps_car_06_cat',\n",
       " 'ps_car_07_cat',\n",
       " 'ps_car_08_cat',\n",
       " 'ps_car_09_cat',\n",
       " 'ps_car_10_cat',\n",
       " 'ps_car_11_cat']"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col</th>\n",
       "      <th>val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ps_ind_01</td>\n",
       "      <td>12.754686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ps_ind_02_cat_1</td>\n",
       "      <td>3.572425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ps_ind_02_cat_2</td>\n",
       "      <td>2.653437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ps_ind_02_cat_3</td>\n",
       "      <td>0.564571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ps_ind_02_cat_4</td>\n",
       "      <td>1.909007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>ps_calc_16_bin</td>\n",
       "      <td>0.205106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>ps_calc_17_bin</td>\n",
       "      <td>0.177377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>ps_calc_18_bin</td>\n",
       "      <td>0.061347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>ps_calc_19_bin</td>\n",
       "      <td>1.272545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>ps_calc_20_bin</td>\n",
       "      <td>0.054855</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>227 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 col        val\n",
       "0          ps_ind_01  12.754686\n",
       "1    ps_ind_02_cat_1   3.572425\n",
       "2    ps_ind_02_cat_2   2.653437\n",
       "3    ps_ind_02_cat_3   0.564571\n",
       "4    ps_ind_02_cat_4   1.909007\n",
       "..               ...        ...\n",
       "222   ps_calc_16_bin   0.205106\n",
       "223   ps_calc_17_bin   0.177377\n",
       "224   ps_calc_18_bin   0.061347\n",
       "225   ps_calc_19_bin   1.272545\n",
       "226   ps_calc_20_bin   0.054855\n",
       "\n",
       "[227 rows x 2 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = t_stat_func(X_train_encoded,y_train)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ps_car_13',\n",
       " 'ps_ind_06_bin',\n",
       " 'ps_reg_03',\n",
       " 'ps_ind_17_bin',\n",
       " 'ps_ind_07_bin',\n",
       " 'ps_reg_02',\n",
       " 'ps_car_04_cat_1',\n",
       " 'ps_car_01_cat_1',\n",
       " 'ps_ind_05_cat_1',\n",
       " 'ps_car_03_cat_1',\n",
       " 'ps_car_15',\n",
       " 'ps_car_02_cat_2',\n",
       " 'ps_car_03_cat_2',\n",
       " 'ps_car_02_cat_1',\n",
       " 'ps_ind_16_bin',\n",
       " 'ps_car_05_cat_1',\n",
       " 'ps_car_07_cat_1',\n",
       " 'ps_ind_15',\n",
       " 'ps_car_07_cat_2',\n",
       " 'ps_reg_01',\n",
       " 'ps_car_09_cat_4',\n",
       " 'ps_car_04_cat_2',\n",
       " 'ps_car_01_cat_2',\n",
       " 'ps_ind_01',\n",
       " 'ps_car_08_cat_2',\n",
       " 'ps_car_11_cat_6',\n",
       " 'ps_ind_05_cat_3',\n",
       " 'ps_car_08_cat_1',\n",
       " 'ps_car_12',\n",
       " 'ps_ind_05_cat_4',\n",
       " 'ps_car_07_cat_3',\n",
       " 'ps_car_01_cat_7',\n",
       " 'ps_car_06_cat_3',\n",
       " 'ps_car_05_cat_3',\n",
       " 'ps_car_04_cat_5',\n",
       " 'ps_car_06_cat_9',\n",
       " 'ps_car_06_cat_7',\n",
       " 'ps_ind_05_cat_6',\n",
       " 'ps_ind_08_bin',\n",
       " 'ps_car_11_cat_25',\n",
       " 'ps_car_01_cat_6',\n",
       " 'ps_car_04_cat_4',\n",
       " 'ps_car_11_cat_7',\n",
       " 'ps_ind_05_cat_5',\n",
       " 'ps_car_05_cat_2',\n",
       " 'ps_car_11_cat_9',\n",
       " 'ps_car_09_cat_2',\n",
       " 'ps_car_06_cat_12',\n",
       " 'ps_car_11_cat_60',\n",
       " 'ps_car_04_cat_3',\n",
       " 'ps_car_06_cat_16',\n",
       " 'ps_car_11_cat_78',\n",
       " 'ps_ind_04_cat_1',\n",
       " 'ps_ind_04_cat_2',\n",
       " 'ps_car_11_cat_36',\n",
       " 'ps_car_11_cat_3',\n",
       " 'ps_ind_03',\n",
       " 'ps_car_11_cat_13',\n",
       " 'ps_car_06_cat_4',\n",
       " 'ps_ind_09_bin',\n",
       " 'ps_car_11_cat_1',\n",
       " 'ps_car_11_cat_56',\n",
       " 'ps_car_06_cat_1',\n",
       " 'ps_car_11_cat_61',\n",
       " 'ps_car_11_cat_31',\n",
       " 'ps_car_06_cat_15',\n",
       " 'ps_ind_02_cat_5',\n",
       " 'ps_ind_04_cat_3',\n",
       " 'ps_car_01_cat_13',\n",
       " 'ps_car_03_cat_3',\n",
       " 'ps_car_06_cat_17',\n",
       " 'ps_ind_12_bin',\n",
       " 'ps_car_01_cat_10',\n",
       " 'ps_car_11_cat_34',\n",
       " 'ps_ind_05_cat_2',\n",
       " 'ps_car_11_cat_62',\n",
       " 'ps_car_11_cat_16',\n",
       " 'ps_ind_14',\n",
       " 'ps_car_11_cat_21',\n",
       " 'ps_car_11_cat_101',\n",
       " 'ps_car_11_cat_76',\n",
       " 'ps_car_11_cat_22',\n",
       " 'ps_car_06_cat_11',\n",
       " 'ps_car_06_cat_6',\n",
       " 'ps_car_11_cat_87',\n",
       " 'ps_car_11_cat_67',\n",
       " 'ps_car_11_cat_77',\n",
       " 'ps_car_09_cat_6',\n",
       " 'ps_car_11_cat_66',\n",
       " 'ps_car_09_cat_5',\n",
       " 'ps_car_11_cat_88',\n",
       " 'ps_car_11_cat_52',\n",
       " 'ps_car_11_cat_57',\n",
       " 'ps_ind_02_cat_1',\n",
       " 'ps_car_14',\n",
       " 'ps_car_11_cat_90',\n",
       " 'ps_car_11_cat_58',\n",
       " 'ps_car_04_cat_7',\n",
       " 'ps_car_11_cat_70',\n",
       " 'ps_car_11_cat_44',\n",
       " 'ps_car_11_cat_5',\n",
       " 'ps_car_11_cat_64',\n",
       " 'ps_car_11_cat_10',\n",
       " 'ps_ind_05_cat_8',\n",
       " 'ps_car_11_cat_4',\n",
       " 'ps_car_11_cat_24',\n",
       " 'ps_car_04_cat_9',\n",
       " 'ps_car_11_cat_8',\n",
       " 'ps_car_11_cat_68',\n",
       " 'ps_car_11_cat_99',\n",
       " 'ps_car_11_cat_33',\n",
       " 'ps_car_11_cat_30',\n",
       " 'ps_car_11_cat_89',\n",
       " 'ps_car_11_cat_47',\n",
       " 'ps_car_11_cat_45',\n",
       " 'ps_car_01_cat_12',\n",
       " 'ps_car_11_cat_2',\n",
       " 'ps_ind_02_cat_2',\n",
       " 'ps_car_11_cat_19',\n",
       " 'ps_car_06_cat_8',\n",
       " 'ps_car_11_cat_98',\n",
       " 'ps_car_06_cat_18',\n",
       " 'ps_car_06_cat_5',\n",
       " 'ps_car_11_cat_97',\n",
       " 'ps_car_11_cat_103',\n",
       " 'ps_car_11_cat_53',\n",
       " 'ps_ind_05_cat_7',\n",
       " 'ps_ind_18_bin',\n",
       " 'ps_car_11_cat_50',\n",
       " 'ps_car_06_cat_2',\n",
       " 'ps_car_11_cat_100',\n",
       " 'ps_car_11_cat_38',\n",
       " 'ps_car_11_cat_74',\n",
       " 'ps_car_11_cat_37',\n",
       " 'ps_ind_02_cat_4',\n",
       " 'ps_car_11_cat_32',\n",
       " 'ps_car_04_cat_10',\n",
       " 'ps_car_11_cat_11',\n",
       " 'ps_car_04_cat_6',\n",
       " 'ps_car_11_cat_104',\n",
       " 'ps_car_02_cat_3',\n",
       " 'ps_car_11_cat_49',\n",
       " 'ps_car_11_cat_85',\n",
       " 'ps_car_11_cat_94',\n",
       " 'ps_car_11_cat_69',\n",
       " 'ps_car_11_cat_80',\n",
       " 'ps_calc_03',\n",
       " 'ps_ind_13_bin',\n",
       " 'ps_car_11_cat_40',\n",
       " 'ps_car_11_cat_17',\n",
       " 'ps_car_01_cat_8',\n",
       " 'ps_car_11_cat_51',\n",
       " 'ps_car_11_cat_84',\n",
       " 'ps_car_01_cat_5',\n",
       " 'ps_car_09_cat_3',\n",
       " 'ps_car_01_cat_4',\n",
       " 'ps_car_11_cat_48',\n",
       " 'ps_car_06_cat_13',\n",
       " 'ps_calc_19_bin',\n",
       " 'ps_car_11_cat_93',\n",
       " 'ps_car_11_cat_96',\n",
       " 'ps_car_11_cat_92',\n",
       " 'ps_car_11_cat_46',\n",
       " 'ps_ind_10_bin',\n",
       " 'ps_car_11_cat_65',\n",
       " 'ps_calc_08',\n",
       " 'ps_car_01_cat_9',\n",
       " 'ps_car_11_cat_20',\n",
       " 'ps_car_11_cat_26',\n",
       " 'ps_car_11_cat_59',\n",
       " 'ps_calc_12',\n",
       " 'ps_car_11_cat_39',\n",
       " 'ps_ind_11_bin',\n",
       " 'ps_car_11_cat_71',\n",
       " 'ps_car_11_cat_54',\n",
       " 'ps_car_09_cat_1',\n",
       " 'ps_car_11_cat_23',\n",
       " 'ps_car_11_cat_95',\n",
       " 'ps_car_11_cat_18',\n",
       " 'ps_car_11_cat_14',\n",
       " 'ps_car_11_cat_35',\n",
       " 'ps_car_04_cat_8',\n",
       " 'ps_calc_09',\n",
       " 'ps_calc_01',\n",
       " 'ps_car_11_cat_12',\n",
       " 'ps_car_11',\n",
       " 'ps_car_11_cat_15',\n",
       " 'ps_car_10_cat_3',\n",
       " 'ps_calc_14',\n",
       " 'ps_car_11_cat_43',\n",
       " 'ps_car_10_cat_2',\n",
       " 'ps_car_11_cat_29',\n",
       " 'ps_car_11_cat_28',\n",
       " 'ps_car_11_cat_81',\n",
       " 'ps_car_11_cat_75',\n",
       " 'ps_car_11_cat_91',\n",
       " 'ps_car_01_cat_11',\n",
       " 'ps_ind_02_cat_3',\n",
       " 'ps_car_11_cat_72',\n",
       " 'ps_car_11_cat_79']"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "power_columns = list(d.sort_values(by='val', ascending = False).head(200).col)\n",
    "power_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9637021916450358\n",
      "ROC_AUC: 0.5874316234940437\n",
      "CPU times: total: 2min 4s\n",
      "Wall time: 13.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "lr = LogisticRegression(max_iter=100)\n",
    "lr.fit(X_train_encoded[power_columns], y_train)\n",
    "\n",
    "prediction = lr.predict(X_test_encoded[power_columns])\n",
    "probs = lr.predict_proba(X_test_encoded[power_columns])\n",
    "\n",
    "print(f'''Accuracy: {accuracy_score(y_test, prediction)}\n",
    "ROC_AUC: {roc_auc_score(y_test, probs[:,1])}''')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
